{"version":3,"sources":["../../src/hooks/use-chat.ts","../../src/utils/fetch-chat-completion.ts"],"sourcesContent":["import { useRef, useState } from \"react\";\nimport { Message, ToolDefinition, FunctionCallHandler, encodeResult } from \"@copilotkit/shared\";\nimport { nanoid } from \"nanoid\";\nimport { fetchAndDecodeChatCompletion } from \"../utils/fetch-chat-completion\";\nimport { CopilotApiConfig } from \"../context\";\n\nexport type UseChatOptions = {\n  /**\n   * The API endpoint that accepts a `{ messages: Message[] }` object and returns\n   * a stream of tokens of the AI chat response. Defaults to `/api/chat`.\n   */\n  api?: string;\n  /**\n   * A unique identifier for the chat. If not provided, a random one will be\n   * generated. When provided, the `useChat` hook with the same `id` will\n   * have shared states across components.\n   */\n  id?: string;\n  /**\n   * System messages of the chat. Defaults to an empty array.\n   */\n  initialMessages?: Message[];\n  /**\n   * Callback function to be called when a function call is received.\n   * If the function returns a `ChatRequest` object, the request will be sent\n   * automatically to the API and will be used to update the chat.\n   */\n  onFunctionCall?: FunctionCallHandler;\n  /**\n   * HTTP headers to be sent with the API request.\n   */\n  headers?: Record<string, string> | Headers;\n  /**\n   * Extra body object to be sent with the API request.\n   * @example\n   * Send a `sessionId` to the API along with the messages.\n   * ```js\n   * useChat({\n   *   body: {\n   *     sessionId: '123',\n   *   }\n   * })\n   * ```\n   */\n  body?: object;\n  /**\n   * Function definitions to be sent to the API.\n   */\n  tools?: ToolDefinition[];\n};\n\nexport type UseChatHelpers = {\n  /** Current messages in the chat */\n  messages: Message[];\n  /**\n   * Append a user message to the chat list. This triggers the API call to fetch\n   * the assistant's response.\n   * @param message The message to append\n   */\n  append: (message: Message) => Promise<void>;\n  /**\n   * Reload the last AI chat response for the given chat history. If the last\n   * message isn't from the assistant, it will request the API to generate a\n   * new response.\n   */\n  reload: () => Promise<void>;\n  /**\n   * Abort the current request immediately, keep the generated tokens if any.\n   */\n  stop: () => void;\n  /** The current value of the input */\n  input: string;\n  /** setState-powered method to update the input value */\n  setInput: React.Dispatch<React.SetStateAction<string>>;\n  /** Whether the API request is in progress */\n  isLoading: boolean;\n};\n\nexport type UseChatOptionsWithCopilotConfig = UseChatOptions & {\n  copilotConfig: CopilotApiConfig;\n};\n\nexport function useChat(options: UseChatOptionsWithCopilotConfig): UseChatHelpers {\n  const [messages, setMessages] = useState<Message[]>([]);\n  const [input, setInput] = useState(\"\");\n  const [isLoading, setIsLoading] = useState(false);\n  const abortControllerRef = useRef<AbortController>();\n\n  const runChatCompletion = async (messages: Message[]): Promise<Message[]> => {\n    setIsLoading(true);\n\n    const newMessages: Message[] = [\n      {\n        id: nanoid(),\n        createdAt: new Date(),\n        content: \"\",\n        role: \"assistant\",\n      },\n    ];\n    const abortController = new AbortController();\n    abortControllerRef.current = abortController;\n\n    setMessages([...messages, ...newMessages]);\n\n    const messagesWithContext = [...(options.initialMessages || []), ...messages];\n    const response = await fetchAndDecodeChatCompletion({\n      copilotConfig: options.copilotConfig,\n      messages: messagesWithContext,\n      tools: options.tools,\n      headers: options.headers,\n      signal: abortController.signal,\n    });\n\n    if (!response.events) {\n      throw new Error(\"Failed to fetch chat completion\");\n    }\n\n    const reader = response.events.getReader();\n\n    // Whether to feed back the new messages to GPT\n    let feedback = false;\n\n    try {\n      while (true) {\n        const { done, value } = await reader.read();\n\n        if (done) {\n          break;\n        }\n\n        let currentMessage = Object.assign({}, newMessages[newMessages.length - 1]);\n\n        if (value.type === \"content\") {\n          if (currentMessage.function_call || currentMessage.role === \"function\") {\n            // Create a new message if the previous one is a function call or result\n            currentMessage = {\n              id: nanoid(),\n              createdAt: new Date(),\n              content: \"\",\n              role: \"assistant\",\n            };\n            newMessages.push(currentMessage);\n          }\n          currentMessage.content += value.content;\n          newMessages[newMessages.length - 1] = currentMessage;\n          setMessages([...messages, ...newMessages]);\n        } else if (value.type === \"result\") {\n          // When we get a result message, it is already complete\n          currentMessage = {\n            id: nanoid(),\n            role: \"function\",\n            content: value.content,\n            name: value.name,\n          };\n          newMessages.push(currentMessage);\n          setMessages([...messages, ...newMessages]);\n\n          // After receiving a result, feed back the new messages to GPT\n          feedback = true;\n        } else if (value.type === \"function\") {\n          // Create a new message if the previous one is not empty\n          if (\n            currentMessage.content != \"\" ||\n            currentMessage.function_call ||\n            currentMessage.role == \"function\"\n          ) {\n            currentMessage = {\n              id: nanoid(),\n              createdAt: new Date(),\n              content: \"\",\n              role: \"assistant\",\n            };\n            newMessages.push(currentMessage);\n          }\n          currentMessage.function_call = {\n            name: value.name,\n            arguments: JSON.stringify(value.arguments),\n            scope: value.scope,\n          };\n\n          newMessages[newMessages.length - 1] = currentMessage;\n          setMessages([...messages, ...newMessages]);\n\n          // Execute the function call\n          try {\n            if (options.onFunctionCall && value.scope === \"client\") {\n              const result = await options.onFunctionCall(messages, currentMessage.function_call);\n\n              currentMessage = {\n                id: nanoid(),\n                role: \"function\",\n                content: encodeResult(result),\n                name: currentMessage.function_call!.name!,\n              };\n              newMessages.push(currentMessage);\n              setMessages([...messages, ...newMessages]);\n\n              // After a function call, feed back the new messages to GPT\n              feedback = true;\n            }\n          } catch (error) {\n            console.error(\"Failed to execute function call\", error);\n            // TODO: Handle error\n            // this should go to the message itself\n          }\n        }\n      }\n\n      // If we want feedback, run the completion again and return the results\n      if (feedback) {\n        return await runChatCompletion([...messages, ...newMessages]);\n      }\n      // otherwise, return the new messages\n      else {\n        return newMessages.slice();\n      }\n    } finally {\n      setIsLoading(false);\n    }\n  };\n\n  const runChatCompletionAndHandleFunctionCall = async (messages: Message[]): Promise<void> => {\n    await runChatCompletion(messages);\n  };\n\n  const append = async (message: Message): Promise<void> => {\n    if (isLoading) {\n      return;\n    }\n    const newMessages = [...messages, message];\n    setMessages(newMessages);\n    return runChatCompletionAndHandleFunctionCall(newMessages);\n  };\n\n  const reload = async (): Promise<void> => {\n    if (isLoading || messages.length === 0) {\n      return;\n    }\n    let newMessages = [...messages];\n    const lastMessage = messages[messages.length - 1];\n\n    if (lastMessage.role === \"assistant\") {\n      newMessages = newMessages.slice(0, -1);\n    }\n    setMessages(newMessages);\n\n    return runChatCompletionAndHandleFunctionCall(newMessages);\n  };\n\n  const stop = (): void => {\n    abortControllerRef.current?.abort();\n  };\n\n  return {\n    messages,\n    append,\n    reload,\n    stop,\n    isLoading,\n    input,\n    setInput,\n  };\n}\n","import {\n  Message,\n  ToolDefinition,\n  ChatCompletionEvent,\n  decodeChatCompletion,\n  parseChatCompletion,\n  decodeChatCompletionAsText,\n  EXCLUDE_FROM_FORWARD_PROPS_KEYS,\n} from \"@copilotkit/shared\";\nimport { CopilotApiConfig } from \"../context\";\n\nexport interface FetchChatCompletionParams {\n  copilotConfig: CopilotApiConfig;\n  model?: string;\n  messages: Message[];\n  tools?: ToolDefinition[];\n  temperature?: number;\n  maxTokens?: number;\n  headers?: Record<string, string> | Headers;\n  body?: object;\n  signal?: AbortSignal;\n}\n\nexport async function fetchChatCompletion({\n  copilotConfig,\n  model,\n  messages,\n  tools,\n  temperature,\n  headers,\n  body,\n  signal,\n}: FetchChatCompletionParams): Promise<Response> {\n  temperature ||= 0.5;\n  tools ||= [];\n\n  // clean up any extra properties from messages\n  const cleanedMessages = messages.map((message) => {\n    const { content, role, name, function_call } = message;\n    return { content, role, name, function_call };\n  });\n\n  const response = await fetch(copilotConfig.chatApiEndpoint, {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n      ...copilotConfig.headers,\n      ...(headers ? { ...headers } : {}),\n    },\n    body: JSON.stringify({\n      model,\n      messages: cleanedMessages,\n      stream: true,\n      ...(tools.length ? { tools } : {}),\n      ...(temperature ? { temperature } : {}),\n      ...(tools.length != 0 ? { tool_choice: \"auto\" } : {}),\n      ...copilotConfig.body,\n      ...copilotConfig.backendOnlyProps,\n      ...(Object.keys(copilotConfig[\"body\"] ?? {}).length > 0\n        ? { [EXCLUDE_FROM_FORWARD_PROPS_KEYS]: Object.keys(copilotConfig[\"body\"] ?? {}) }\n        : {}),\n      ...(body ? { ...body } : {}),\n    }),\n    signal,\n  });\n\n  return response;\n}\n\nexport interface DecodedChatCompletionResponse extends Response {\n  events: ReadableStream<ChatCompletionEvent> | null;\n}\n\nexport async function fetchAndDecodeChatCompletion(\n  params: FetchChatCompletionParams,\n): Promise<DecodedChatCompletionResponse> {\n  const response = await fetchChatCompletion(params);\n  if (!response.ok || !response.body) {\n    return { ...response, events: null };\n  }\n  const events = await decodeChatCompletion(parseChatCompletion(response.body));\n  return { ...response, events };\n}\n\nexport interface DecodedChatCompletionResponseAsText extends Response {\n  events: ReadableStream<string> | null;\n}\n\nexport async function fetchAndDecodeChatCompletionAsText(\n  params: FetchChatCompletionParams,\n): Promise<DecodedChatCompletionResponseAsText> {\n  const response = await fetchChatCompletion(params);\n  if (!response.ok || !response.body) {\n    return { ...response, events: null };\n  }\n  const events = await decodeChatCompletionAsText(\n    decodeChatCompletion(parseChatCompletion(response.body)),\n  );\n  return { ...response, events };\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAAiC;AACjC,IAAAA,iBAA2E;AAC3E,oBAAuB;;;ACFvB,oBAQO;AAeP,SAAsB,oBAAoB,IASO;AAAA,6CATP;AAAA,IACxC;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,GAAiD;AAhCjD;AAiCE,kCAAgB;AAChB,sBAAU,CAAC;AAGX,UAAM,kBAAkB,SAAS,IAAI,CAAC,YAAY;AAChD,YAAM,EAAE,SAAS,MAAM,MAAM,cAAc,IAAI;AAC/C,aAAO,EAAE,SAAS,MAAM,MAAM,cAAc;AAAA,IAC9C,CAAC;AAED,UAAM,WAAW,MAAM,MAAM,cAAc,iBAAiB;AAAA,MAC1D,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,SACb,cAAc,UACb,UAAU,mBAAK,WAAY,CAAC;AAAA,MAElC,MAAM,KAAK,UAAU;AAAA,QACnB;AAAA,QACA,UAAU;AAAA,QACV,QAAQ;AAAA,SACJ,MAAM,SAAS,EAAE,MAAM,IAAI,CAAC,IAC5B,cAAc,EAAE,YAAY,IAAI,CAAC,IACjC,MAAM,UAAU,IAAI,EAAE,aAAa,OAAO,IAAI,CAAC,IAChD,cAAc,OACd,cAAc,mBACb,OAAO,MAAK,mBAAc,MAAM,MAApB,YAAyB,CAAC,CAAC,EAAE,SAAS,IAClD,EAAE,CAAC,6CAA+B,GAAG,OAAO,MAAK,mBAAc,MAAM,MAApB,YAAyB,CAAC,CAAC,EAAE,IAC9E,CAAC,IACD,OAAO,mBAAK,QAAS,CAAC,EAC3B;AAAA,MACD;AAAA,IACF,CAAC;AAED,WAAO;AAAA,EACT;AAAA;AAMA,SAAsB,6BACpB,QACwC;AAAA;AACxC,UAAM,WAAW,MAAM,oBAAoB,MAAM;AACjD,QAAI,CAAC,SAAS,MAAM,CAAC,SAAS,MAAM;AAClC,aAAO,iCAAK,WAAL,EAAe,QAAQ,KAAK;AAAA,IACrC;AACA,UAAM,SAAS,UAAM,wCAAqB,mCAAoB,SAAS,IAAI,CAAC;AAC5E,WAAO,iCAAK,WAAL,EAAe,OAAO;AAAA,EAC/B;AAAA;;;ADAO,SAAS,QAAQ,SAA0D;AAChF,QAAM,CAAC,UAAU,WAAW,QAAI,uBAAoB,CAAC,CAAC;AACtD,QAAM,CAAC,OAAO,QAAQ,QAAI,uBAAS,EAAE;AACrC,QAAM,CAAC,WAAW,YAAY,QAAI,uBAAS,KAAK;AAChD,QAAM,yBAAqB,qBAAwB;AAEnD,QAAM,oBAAoB,CAAOC,cAA4C;AAC3E,iBAAa,IAAI;AAEjB,UAAM,cAAyB;AAAA,MAC7B;AAAA,QACE,QAAI,sBAAO;AAAA,QACX,WAAW,oBAAI,KAAK;AAAA,QACpB,SAAS;AAAA,QACT,MAAM;AAAA,MACR;AAAA,IACF;AACA,UAAM,kBAAkB,IAAI,gBAAgB;AAC5C,uBAAmB,UAAU;AAE7B,gBAAY,CAAC,GAAGA,WAAU,GAAG,WAAW,CAAC;AAEzC,UAAM,sBAAsB,CAAC,GAAI,QAAQ,mBAAmB,CAAC,GAAI,GAAGA,SAAQ;AAC5E,UAAM,WAAW,MAAM,6BAA6B;AAAA,MAClD,eAAe,QAAQ;AAAA,MACvB,UAAU;AAAA,MACV,OAAO,QAAQ;AAAA,MACf,SAAS,QAAQ;AAAA,MACjB,QAAQ,gBAAgB;AAAA,IAC1B,CAAC;AAED,QAAI,CAAC,SAAS,QAAQ;AACpB,YAAM,IAAI,MAAM,iCAAiC;AAAA,IACnD;AAEA,UAAM,SAAS,SAAS,OAAO,UAAU;AAGzC,QAAI,WAAW;AAEf,QAAI;AACF,aAAO,MAAM;AACX,cAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAE1C,YAAI,MAAM;AACR;AAAA,QACF;AAEA,YAAI,iBAAiB,OAAO,OAAO,CAAC,GAAG,YAAY,YAAY,SAAS,CAAC,CAAC;AAE1E,YAAI,MAAM,SAAS,WAAW;AAC5B,cAAI,eAAe,iBAAiB,eAAe,SAAS,YAAY;AAEtE,6BAAiB;AAAA,cACf,QAAI,sBAAO;AAAA,cACX,WAAW,oBAAI,KAAK;AAAA,cACpB,SAAS;AAAA,cACT,MAAM;AAAA,YACR;AACA,wBAAY,KAAK,cAAc;AAAA,UACjC;AACA,yBAAe,WAAW,MAAM;AAChC,sBAAY,YAAY,SAAS,CAAC,IAAI;AACtC,sBAAY,CAAC,GAAGA,WAAU,GAAG,WAAW,CAAC;AAAA,QAC3C,WAAW,MAAM,SAAS,UAAU;AAElC,2BAAiB;AAAA,YACf,QAAI,sBAAO;AAAA,YACX,MAAM;AAAA,YACN,SAAS,MAAM;AAAA,YACf,MAAM,MAAM;AAAA,UACd;AACA,sBAAY,KAAK,cAAc;AAC/B,sBAAY,CAAC,GAAGA,WAAU,GAAG,WAAW,CAAC;AAGzC,qBAAW;AAAA,QACb,WAAW,MAAM,SAAS,YAAY;AAEpC,cACE,eAAe,WAAW,MAC1B,eAAe,iBACf,eAAe,QAAQ,YACvB;AACA,6BAAiB;AAAA,cACf,QAAI,sBAAO;AAAA,cACX,WAAW,oBAAI,KAAK;AAAA,cACpB,SAAS;AAAA,cACT,MAAM;AAAA,YACR;AACA,wBAAY,KAAK,cAAc;AAAA,UACjC;AACA,yBAAe,gBAAgB;AAAA,YAC7B,MAAM,MAAM;AAAA,YACZ,WAAW,KAAK,UAAU,MAAM,SAAS;AAAA,YACzC,OAAO,MAAM;AAAA,UACf;AAEA,sBAAY,YAAY,SAAS,CAAC,IAAI;AACtC,sBAAY,CAAC,GAAGA,WAAU,GAAG,WAAW,CAAC;AAGzC,cAAI;AACF,gBAAI,QAAQ,kBAAkB,MAAM,UAAU,UAAU;AACtD,oBAAM,SAAS,MAAM,QAAQ,eAAeA,WAAU,eAAe,aAAa;AAElF,+BAAiB;AAAA,gBACf,QAAI,sBAAO;AAAA,gBACX,MAAM;AAAA,gBACN,aAAS,6BAAa,MAAM;AAAA,gBAC5B,MAAM,eAAe,cAAe;AAAA,cACtC;AACA,0BAAY,KAAK,cAAc;AAC/B,0BAAY,CAAC,GAAGA,WAAU,GAAG,WAAW,CAAC;AAGzC,yBAAW;AAAA,YACb;AAAA,UACF,SAAS,OAAP;AACA,oBAAQ,MAAM,mCAAmC,KAAK;AAAA,UAGxD;AAAA,QACF;AAAA,MACF;AAGA,UAAI,UAAU;AACZ,eAAO,MAAM,kBAAkB,CAAC,GAAGA,WAAU,GAAG,WAAW,CAAC;AAAA,MAC9D,OAEK;AACH,eAAO,YAAY,MAAM;AAAA,MAC3B;AAAA,IACF,UAAE;AACA,mBAAa,KAAK;AAAA,IACpB;AAAA,EACF;AAEA,QAAM,yCAAyC,CAAOA,cAAuC;AAC3F,UAAM,kBAAkBA,SAAQ;AAAA,EAClC;AAEA,QAAM,SAAS,CAAO,YAAoC;AACxD,QAAI,WAAW;AACb;AAAA,IACF;AACA,UAAM,cAAc,CAAC,GAAG,UAAU,OAAO;AACzC,gBAAY,WAAW;AACvB,WAAO,uCAAuC,WAAW;AAAA,EAC3D;AAEA,QAAM,SAAS,MAA2B;AACxC,QAAI,aAAa,SAAS,WAAW,GAAG;AACtC;AAAA,IACF;AACA,QAAI,cAAc,CAAC,GAAG,QAAQ;AAC9B,UAAM,cAAc,SAAS,SAAS,SAAS,CAAC;AAEhD,QAAI,YAAY,SAAS,aAAa;AACpC,oBAAc,YAAY,MAAM,GAAG,EAAE;AAAA,IACvC;AACA,gBAAY,WAAW;AAEvB,WAAO,uCAAuC,WAAW;AAAA,EAC3D;AAEA,QAAM,OAAO,MAAY;AAzP3B;AA0PI,6BAAmB,YAAnB,mBAA4B;AAAA,EAC9B;AAEA,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACF;","names":["import_shared","messages"]}