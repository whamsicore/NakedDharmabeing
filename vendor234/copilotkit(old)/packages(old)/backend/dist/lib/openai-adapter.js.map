{"version":3,"sources":["../../src/lib/openai-adapter.ts","../../src/utils/openai.ts"],"sourcesContent":["import OpenAI from \"openai\";\nimport { CopilotKitServiceAdapter } from \"../types/service-adapter\";\nimport { limitOpenAIMessagesToTokenCount, maxTokensForOpenAIModel } from \"../utils/openai\";\n\nconst DEFAULT_MODEL = \"gpt-4-1106-preview\";\n\nexport interface OpenAIAdapterParams {\n  openai?: OpenAI;\n  model?: string;\n}\n\nexport class OpenAIAdapter implements CopilotKitServiceAdapter {\n  private openai: OpenAI;\n  private model: string = DEFAULT_MODEL;\n  constructor(params?: OpenAIAdapterParams) {\n    this.openai = params?.openai || new OpenAI({});\n    if (params?.model) {\n      this.model = params.model;\n    }\n  }\n\n  stream(forwardedProps: any): ReadableStream {\n    // copy forwardedProps to avoid modifying the original object\n    forwardedProps = { ...forwardedProps };\n\n    // Remove tools if there are none to avoid OpenAI API errors\n    // when sending an empty array of tools\n    if (forwardedProps.tools && forwardedProps.tools.length === 0) {\n      delete forwardedProps.tools;\n    }\n\n    const messages = limitOpenAIMessagesToTokenCount(\n      forwardedProps.messages || [],\n      forwardedProps.tools || [],\n      maxTokensForOpenAIModel(forwardedProps.model || DEFAULT_MODEL),\n    );\n\n    return this.openai.beta.chat.completions\n      .stream({\n        model: this.model,\n        ...forwardedProps,\n        stream: true,\n        messages: messages as any,\n      })\n      .toReadableStream();\n  }\n}\n","import { Message, ToolDefinition, ChatCompletionChunk, encodeResult } from \"@copilotkit/shared\";\n\nexport function writeChatCompletionChunk(\n  controller: ReadableStreamDefaultController<any>,\n  chunk: ChatCompletionChunk,\n) {\n  const payload = new TextEncoder().encode(\"data: \" + JSON.stringify(chunk) + \"\\n\\n\");\n  controller!.enqueue(payload);\n}\n\nexport function writeChatCompletionContent(\n  controller: ReadableStreamDefaultController<any>,\n  content: string = \"\",\n  toolCalls?: any,\n) {\n  const chunk: ChatCompletionChunk = {\n    choices: [\n      {\n        delta: {\n          role: \"assistant\",\n          content: content,\n          ...(toolCalls ? { tool_calls: toolCalls } : {}),\n        },\n      },\n    ],\n  };\n\n  writeChatCompletionChunk(controller, chunk);\n}\n\nexport function writeChatCompletionResult(\n  controller: ReadableStreamDefaultController<any>,\n  functionName: string,\n  result: any,\n) {\n  let resultString = encodeResult(result);\n\n  const chunk: ChatCompletionChunk = {\n    choices: [\n      {\n        delta: {\n          role: \"function\",\n          content: resultString,\n          name: functionName,\n        },\n      },\n    ],\n  };\n\n  writeChatCompletionChunk(controller, chunk);\n}\n\nexport function writeChatCompletionEnd(controller: ReadableStreamDefaultController<any>) {\n  const payload = new TextEncoder().encode(\"data: [DONE]\\n\\n\");\n  controller.enqueue(payload);\n}\n\nexport function limitOpenAIMessagesToTokenCount(\n  messages: Message[],\n  tools: ToolDefinition[],\n  maxTokens: number,\n): Message[] {\n  const result: Message[] = [];\n  const toolsNumTokens = countToolsTokens(tools);\n  if (toolsNumTokens > maxTokens) {\n    throw new Error(`Too many tokens in function definitions: ${toolsNumTokens} > ${maxTokens}`);\n  }\n  maxTokens -= toolsNumTokens;\n\n  for (const message of messages) {\n    if (message.role === \"system\") {\n      const numTokens = countMessageTokens(message);\n      maxTokens -= numTokens;\n\n      if (maxTokens < 0) {\n        throw new Error(\"Not enough tokens for system message.\");\n      }\n    }\n  }\n\n  let cutoff: boolean = false;\n\n  const reversedMessages = [...messages].reverse();\n  for (const message of reversedMessages) {\n    if (message.role === \"system\") {\n      result.unshift(message);\n      continue;\n    } else if (cutoff) {\n      continue;\n    }\n    let numTokens = countMessageTokens(message);\n    if (maxTokens < numTokens) {\n      cutoff = true;\n      continue;\n    }\n    result.unshift(message);\n    maxTokens -= numTokens;\n  }\n\n  return result;\n}\n\nexport function maxTokensForOpenAIModel(model: string): number {\n  return maxTokensByModel[model] || DEFAULT_MAX_TOKENS;\n}\n\nconst DEFAULT_MAX_TOKENS = 8192;\n\nconst maxTokensByModel: { [key: string]: number } = {\n  \"gpt-3.5-turbo\": 4097,\n  \"gpt-3.5-turbo-16k\": 16385,\n  \"gpt-4\": 8192,\n  \"gpt-4-1106-preview\": 8192,\n  \"gpt-4-32k\": 32768,\n  \"gpt-3.5-turbo-0301\": 4097,\n  \"gpt-4-0314\": 8192,\n  \"gpt-4-32k-0314\": 32768,\n  \"gpt-3.5-turbo-0613\": 4097,\n  \"gpt-4-0613\": 8192,\n  \"gpt-4-32k-0613\": 32768,\n  \"gpt-3.5-turbo-16k-0613\": 16385,\n};\n\nfunction countToolsTokens(functions: ToolDefinition[]): number {\n  if (functions.length === 0) {\n    return 0;\n  }\n  const json = JSON.stringify(functions);\n  return countTokens(json);\n}\n\nfunction countMessageTokens(message: Message): number {\n  if (message.content) {\n    return countTokens(message.content);\n  } else if (message.function_call) {\n    return countTokens(JSON.stringify(message.function_call));\n  }\n  return 0;\n}\n\nfunction countTokens(text: string): number {\n  return text.length / 3;\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAAmB;;;ACAnB,oBAA2E;AAyDpE,SAAS,gCACd,UACA,OACA,WACW;AACX,QAAM,SAAoB,CAAC;AAC3B,QAAM,iBAAiB,iBAAiB,KAAK;AAC7C,MAAI,iBAAiB,WAAW;AAC9B,UAAM,IAAI,MAAM,4CAA4C,oBAAoB,WAAW;AAAA,EAC7F;AACA,eAAa;AAEb,aAAW,WAAW,UAAU;AAC9B,QAAI,QAAQ,SAAS,UAAU;AAC7B,YAAM,YAAY,mBAAmB,OAAO;AAC5C,mBAAa;AAEb,UAAI,YAAY,GAAG;AACjB,cAAM,IAAI,MAAM,uCAAuC;AAAA,MACzD;AAAA,IACF;AAAA,EACF;AAEA,MAAI,SAAkB;AAEtB,QAAM,mBAAmB,CAAC,GAAG,QAAQ,EAAE,QAAQ;AAC/C,aAAW,WAAW,kBAAkB;AACtC,QAAI,QAAQ,SAAS,UAAU;AAC7B,aAAO,QAAQ,OAAO;AACtB;AAAA,IACF,WAAW,QAAQ;AACjB;AAAA,IACF;AACA,QAAI,YAAY,mBAAmB,OAAO;AAC1C,QAAI,YAAY,WAAW;AACzB,eAAS;AACT;AAAA,IACF;AACA,WAAO,QAAQ,OAAO;AACtB,iBAAa;AAAA,EACf;AAEA,SAAO;AACT;AAEO,SAAS,wBAAwB,OAAuB;AAC7D,SAAO,iBAAiB,KAAK,KAAK;AACpC;AAEA,IAAM,qBAAqB;AAE3B,IAAM,mBAA8C;AAAA,EAClD,iBAAiB;AAAA,EACjB,qBAAqB;AAAA,EACrB,SAAS;AAAA,EACT,sBAAsB;AAAA,EACtB,aAAa;AAAA,EACb,sBAAsB;AAAA,EACtB,cAAc;AAAA,EACd,kBAAkB;AAAA,EAClB,sBAAsB;AAAA,EACtB,cAAc;AAAA,EACd,kBAAkB;AAAA,EAClB,0BAA0B;AAC5B;AAEA,SAAS,iBAAiB,WAAqC;AAC7D,MAAI,UAAU,WAAW,GAAG;AAC1B,WAAO;AAAA,EACT;AACA,QAAM,OAAO,KAAK,UAAU,SAAS;AACrC,SAAO,YAAY,IAAI;AACzB;AAEA,SAAS,mBAAmB,SAA0B;AACpD,MAAI,QAAQ,SAAS;AACnB,WAAO,YAAY,QAAQ,OAAO;AAAA,EACpC,WAAW,QAAQ,eAAe;AAChC,WAAO,YAAY,KAAK,UAAU,QAAQ,aAAa,CAAC;AAAA,EAC1D;AACA,SAAO;AACT;AAEA,SAAS,YAAY,MAAsB;AACzC,SAAO,KAAK,SAAS;AACvB;;;AD1IA,IAAM,gBAAgB;AAOf,IAAM,gBAAN,MAAwD;AAAA,EAG7D,YAAY,QAA8B;AAD1C,SAAQ,QAAgB;AAEtB,SAAK,UAAS,iCAAQ,WAAU,IAAI,cAAAA,QAAO,CAAC,CAAC;AAC7C,QAAI,iCAAQ,OAAO;AACjB,WAAK,QAAQ,OAAO;AAAA,IACtB;AAAA,EACF;AAAA,EAEA,OAAO,gBAAqC;AAE1C,qBAAiB,EAAE,GAAG,eAAe;AAIrC,QAAI,eAAe,SAAS,eAAe,MAAM,WAAW,GAAG;AAC7D,aAAO,eAAe;AAAA,IACxB;AAEA,UAAM,WAAW;AAAA,MACf,eAAe,YAAY,CAAC;AAAA,MAC5B,eAAe,SAAS,CAAC;AAAA,MACzB,wBAAwB,eAAe,SAAS,aAAa;AAAA,IAC/D;AAEA,WAAO,KAAK,OAAO,KAAK,KAAK,YAC1B,OAAO;AAAA,MACN,OAAO,KAAK;AAAA,MACZ,GAAG;AAAA,MACH,QAAQ;AAAA,MACR;AAAA,IACF,CAAC,EACA,iBAAiB;AAAA,EACtB;AACF;","names":["OpenAI"]}